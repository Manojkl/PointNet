{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pointnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4Vq46sLnU7UYxMgLDXsjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manojkl/Point_net/blob/main/Pointnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daw-xNGM3Zt6"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from torchvision import transforms, utils\n",
        "import os\n",
        "import torch\n",
        "import scipy.spatial.distance\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keyL8sWA3dQ9",
        "outputId": "5c0d4306-b5f5-48ce-ab7f-fc8cb0262793"
      },
      "source": [
        "!pip install path.py;"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting path.py\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/04/130b7a538c25693c85c4dee7e25d126ebf5511b1eb7320e64906687b159e/path.py-12.5.0-py3-none-any.whl\n",
            "Collecting path\n",
            "  Downloading https://files.pythonhosted.org/packages/79/07/fff7123a7fb78aaa0757a70a4ab4bc0f74796c61ddfb12a40122462eeabb/path-15.1.0-py3-none-any.whl\n",
            "Installing collected packages: path, path.py\n",
            "Successfully installed path-15.1.0 path.py-12.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHx1No3p3gRK"
      },
      "source": [
        "from path import Path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRnLeyge31p4",
        "outputId": "c4e24889-e9bf-461e-d756-61d751f28fc4"
      },
      "source": [
        "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
        "!unzip -q ModelNet10.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-15 22:54:00--  http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Resolving 3dvision.princeton.edu (3dvision.princeton.edu)... 128.112.136.61\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.61|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473402300 (451M) [application/zip]\n",
            "Saving to: ‘ModelNet10.zip’\n",
            "\n",
            "ModelNet10.zip      100%[===================>] 451.47M  45.2MB/s    in 10s     \n",
            "\n",
            "2021-02-15 22:54:11 (43.3 MB/s) - ‘ModelNet10.zip’ saved [473402300/473402300]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnt1jGrb4AHo"
      },
      "source": [
        "path = Path(\"ModelNet10\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR_QqoJG4SQ4"
      },
      "source": [
        "def read_off(file):\n",
        "    if 'OFF' != file.readline().strip():\n",
        "        raise('Not a valid OFF header')\n",
        "    # Note: readline reads one line at a time and next time you again call it it remembers the last line stopped reading. Hence onces you finish reading the vertices the next line in faces contains the deatils about the faces the vertices connected to.\n",
        "    # Second line of the file contains details abou the number of vertices and number of faces in a file\n",
        "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
        "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
        "    # Ignore the first integer using [1:]\n",
        "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
        "    # print(faces)\n",
        "    return verts, faces\n",
        "    \n",
        "with open(path/\"bed/train/bed_0001.off\", 'r') as f:\n",
        "    mesh = read_off(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9nwUiWt4tjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e210cfd6-4d50-4dc9-d4ed-f5947dc5fd1a"
      },
      "source": [
        "with open(path/\"bed/train/bed_0001.off\", 'r') as f:\n",
        "    file = f\n",
        "    if 'OFF' != file.readline().strip():\n",
        "        raise('Not a valid OFF header')\n",
        "    for s in  for i_face in range(n_faces)]\n",
        "      print(s)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2095\n",
            "1807\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGBjQZ9pBztc",
        "outputId": "9de0166e-81a8-40ae-a6f6-11b0ac48db05"
      },
      "source": [
        "# Read the number of vertices and faces\n",
        "verts, faces = mesh\n",
        "# Intialize a numpy array for every faces\n",
        "areas = np.zeros((len(faces)))\n",
        "# Vertices is connverted into numpy array \n",
        "verts = np.array(verts)\n",
        "print(len(areas))\n",
        "print(verts)\n",
        "\n",
        "# function to calculate triangle area by its vertices\n",
        "# https://en.wikipedia.org/wiki/Heron%27s_formula\n",
        "\n",
        "def triangle_area(pt1, pt2, pt3):\n",
        "    side_a = np.linalg.norm(pt1 - pt2)\n",
        "    side_b = np.linalg.norm(pt2 - pt3)\n",
        "    side_c = np.linalg.norm(pt3 - pt1)\n",
        "    s = 0.5 * ( side_a + side_b + side_c)\n",
        "    return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "# we calculate areas of all faces in our mesh\n",
        "# faces = 4 5 6\n",
        "# Vertices give us the location of a point in 3D space and three point joining forms a mesh or area. \n",
        "for i in range(len(areas)):\n",
        "    areas[i] = (triangle_area(verts[faces[i][0]],\n",
        "                              verts[faces[i][1]],\n",
        "                              verts[faces[i][2]]))\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1807\n",
            "[[ 30.       -35.027505 -12.25    ]\n",
            " [ 30.       -41.027505 -12.25    ]\n",
            " [ 19.75      39.972495   0.75    ]\n",
            " ...\n",
            " [ -2.143     34.260195   0.75    ]\n",
            " [-26.143     17.260195   0.75    ]\n",
            " [-26.143     34.260195   0.75    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FjdXNuD2663"
      },
      "source": [
        "\n",
        "k = 3000\n",
        "# we sample 'k' faces with probabilities proportional to their areas\n",
        "# weights are used to create a distribution.\n",
        "# they don't have to sum up to one.\n",
        "# mylist = [\"apple\", \"banana\", \"cherry\"]\n",
        "# print(random.choices(mylist, weights = [10, 1, 1], k = 14))\n",
        "# Return a list with 14 items.\n",
        "# The list should contain a randomly selection of the values from a specified list, and there should be 10 times higher possibility to select \"apple\" than the other two:\n",
        "\n",
        "sampled_faces = (random.choices(faces, \n",
        "                                weights=areas,\n",
        "                                k=k))\n",
        "\n",
        "# function to sample points on a triangle surface\n",
        "def sample_point(pt1, pt2, pt3):\n",
        "    # barycentric coordinates on a triangle\n",
        "    # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "    # https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-rendering-a-triangle/barycentric-coordinates#:~:text=Barycentric%20coordinates%20are%20also%20known,A%2C%20B%2C%20C).\n",
        "    # random.random() generates random value between 0 and 1.\n",
        "    s, t = sorted([random.random(), random.random()])\n",
        "    f = lambda i: s * pt1[i] + (t-s) * pt2[i] + (1-t) * pt3[i]\n",
        "    return (f(0), f(1), f(2))\n",
        " \n",
        "pointcloud = np.zeros((k, 3))\n",
        "\n",
        "# sample points on chosen faces for the point cloud of size 'k'\n",
        "for i in range(len(sampled_faces)):\n",
        "    pointcloud[i] = (sample_point(verts[sampled_faces[i][0]],\n",
        "                                  verts[sampled_faces[i][1]],\n",
        "                                  verts[sampled_faces[i][2]]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1kmj6tTxKCE"
      },
      "source": [
        "\n",
        "# normalize\n",
        "norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "# rotation around z-axis\n",
        "theta = random.random() * 2. * math.pi # rotation angle\n",
        "rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "                       [ math.sin(theta),  math.cos(theta),    0],\n",
        "                       [0,                             0,      1]])\n",
        "\n",
        "rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "\n",
        "# add some noise\n",
        "noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "noisy_pointcloud = rot_pointcloud + noise"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbK6i5kk4YP6"
      },
      "source": [
        "class PointSampler(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "    \n",
        "    def triangle_area(self, pt1, pt2, pt3):\n",
        "        side_a = np.linalg.norm(pt1 - pt2)\n",
        "        side_b = np.linalg.norm(pt2 - pt3)\n",
        "        side_c = np.linalg.norm(pt3 - pt1)\n",
        "        s = 0.5 * ( side_a + side_b + side_c)\n",
        "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "    def sample_point(self, pt1, pt2, pt3):\n",
        "        # barycentric coordinates on a triangle\n",
        "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "        s, t = sorted([random.random(), random.random()])\n",
        "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "        return (f(0), f(1), f(2))\n",
        "        \n",
        "    \n",
        "    def __call__(self, mesh):\n",
        "        verts, faces = mesh\n",
        "        verts = np.array(verts)\n",
        "        areas = np.zeros((len(faces)))\n",
        "\n",
        "        for i in range(len(areas)):\n",
        "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
        "                                           verts[faces[i][1]],\n",
        "                                           verts[faces[i][2]]))\n",
        "            \n",
        "        sampled_faces = (random.choices(faces, \n",
        "                                      weights=areas,\n",
        "                                      cum_weights=None,\n",
        "                                      k=self.output_size))\n",
        "        \n",
        "        sampled_points = np.zeros((self.output_size, 3))\n",
        "\n",
        "        for i in range(len(sampled_faces)):\n",
        "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
        "                                                   verts[sampled_faces[i][1]],\n",
        "                                                   verts[sampled_faces[i][2]]))\n",
        "        \n",
        "        return sampled_points"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSE3sfk13hlL"
      },
      "source": [
        "\n",
        "class RandRotation_z(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        theta = random.random() * 2. * math.pi\n",
        "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "                               [ math.sin(theta),  math.cos(theta),    0],\n",
        "                               [0,                             0,      1]])\n",
        "        \n",
        "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "        return  rot_pointcloud\n",
        "    \n",
        "class RandomNoise(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "    \n",
        "        noisy_pointcloud = pointcloud + noise\n",
        "        return  noisy_pointcloud"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQcik6s14eDy"
      },
      "source": [
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "        \n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBRpcWXF3lio"
      },
      "source": [
        "rot_pointcloud = RandRotation_z()(norm_pointcloud)\n",
        "noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlmKnPdS3ZAD"
      },
      "source": [
        "class ToTensor(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        return torch.from_numpy(pointcloud)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aulnx_aP3aYS"
      },
      "source": [
        "def default_transforms():\n",
        "    return transforms.Compose([\n",
        "                                PointSampler(1024),\n",
        "                                Normalize(),\n",
        "                                ToTensor()\n",
        "                              ])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Jy3BUv41xi"
      },
      "source": [
        "class PointCloudData(Dataset):\n",
        "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
        "        self.root_dir = root_dir\n",
        "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "        self.transforms = transform if not valid else default_transforms()\n",
        "        self.valid = valid\n",
        "        self.files = []\n",
        "        for category in self.classes.keys():\n",
        "            new_dir = root_dir/Path(category)/folder\n",
        "            for file in os.listdir(new_dir):\n",
        "                if file.endswith('.off'):\n",
        "                    sample = {}\n",
        "                    sample['pcd_path'] = new_dir/file\n",
        "                    sample['category'] = category\n",
        "                    self.files.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __preproc__(self, file):\n",
        "        verts, faces = read_off(file)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms((verts, faces))\n",
        "        return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files[idx]['pcd_path']\n",
        "        category = self.files[idx]['category']\n",
        "        with open(pcd_path, 'r') as f:\n",
        "            pointcloud = self.__preproc__(f)\n",
        "        return {'pointcloud': pointcloud, \n",
        "                'category': self.classes[category]}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du831pQ94DnI"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                    PointSampler(1024),\n",
        "                    Normalize(),\n",
        "                    RandRotation_z(),\n",
        "                    RandomNoise(),\n",
        "                    ToTensor()\n",
        "                    ])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kKbCO-64lta"
      },
      "source": [
        "train_ds = PointCloudData(path, transform=train_transforms)\n",
        "valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnl9B2tZ47gj"
      },
      "source": [
        "inv_classes = {i: cat for cat, i in train_ds.classes.items()};"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAdFthaN4_rY",
        "outputId": "87d921c0-a38a-48da-b26c-c847fb3d3855"
      },
      "source": [
        "print('Train dataset size: ', len(train_ds))\n",
        "print('Valid dataset size: ', len(valid_ds))\n",
        "print('Number of classes: ', len(train_ds.classes))\n",
        "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n",
        "print('Class: ', inv_classes[train_ds[0]['category']])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset size:  3991\n",
            "Valid dataset size:  908\n",
            "Number of classes:  10\n",
            "Sample pointcloud shape:  torch.Size([1024, 3])\n",
            "Class:  bathtub\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf7BBGIf5C0S"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlfSAhaW-64o"
      },
      "source": [
        "import torch\n",
        "\n",
        "# The torch.nn import gives us access to some helpful neural network things, \n",
        "# such as various neural network layer types (things like regular fully-connected layers, convolutional layers (for imagery), recurrent layers...etc)\n",
        "import torch.nn as nn \n",
        "\n",
        "# The torch.nn.functional area specifically gives us access to some handy functions that we might not want to write ourselves. \n",
        "# We will be using the relu or \"rectified linear\" activation function for our neurons. Instead of writing all of the code for these things, we can just import them\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# In PyTorch, we use torch.nn to build layers. For example, in __iniit__, we configure different trainable layers including convolution and affine layers with nn.Conv2d and nn.Linear respectively.\n",
        "# We create the method forward to compute the network output. It contains functionals linking layers already configured in __iniit__ to form a computation graph. Functionals include ReLU and max poolings.\n",
        "\n",
        "# nn.Conv1d(in_channels=n_hidden, out_channels=n_output, kernel_size=1)\n",
        "# 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
        "# self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "\n",
        "\n",
        "\n",
        "# CLASS torch.nn.Linear(in_features, out_features, bias=True)\n",
        "# Applies a linear transformation to the incoming data: y = x*W^T + b\n",
        "# Parameters:\n",
        "# in_features – size of each input sample (i.e. size of x)\n",
        "# out_features – size of each output sample (i.e. size of y)\n",
        "\n",
        "# Batch norm is about making mean and variance of a batch of example to be 0 and 1 respectively.\n",
        "# Batch normalization is a technique for training very deep neural networks that normalizes the contributions to a layer for every mini-batch.\n",
        "# This has the impact of settling the learning process and drastically decreasing the number of training epochs required to train deep neural networks\n",
        "# torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "# torch.eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \n",
        "# Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
        "\n",
        "\n",
        "class Tnet(nn.Module):\n",
        "\n",
        "    def __init__(self, k=3):\n",
        "      # The super() function is used to give access to methods and properties of a parent or sibling class.\n",
        "      super().__init__()\n",
        "      self.k = k\n",
        "      self.conv1 = nn.Conv1d(k, 64, 1)\n",
        "      self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "      self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "      self.fc1 = nn.Linear(1024, 512)\n",
        "      self.fc2 = nn.Linear(512, 256)\n",
        "      self.fc3 = nn.Linear(256, k*k)\n",
        "\n",
        "      self.bn1 =  nn.BatchNorm1d(64)\n",
        "      self.bn2 =  nn.BatchNorm1d(128)\n",
        "      self.bn3 =  nn.BatchNorm1d(1024)\n",
        "      self.bn4 =  nn.BatchNorm1d(512)\n",
        "      self.bn5 =  nn.BatchNorm1d(256)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "      bs = input.size(0)\n",
        "      xb = F.relu(self.bn1(self.conv1(input)))\n",
        "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
        "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "      flat = nn.Flatten(1)(pool)\n",
        "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
        "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
        "\n",
        "      #Initializing an identity\n",
        "\n",
        "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "\n",
        "      if xb.is_cuda:\n",
        "        init=init.cuda()\n",
        "      # add identity to the output\n",
        "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "      return matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBqLi_REAWC7"
      },
      "source": [
        "class Transform(nn.Module):\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_transform = Tnet(k=3)\n",
        "        self.feature_transform = Tnet(k=64)\n",
        "        self.conv1 = nn.Conv1d(3,64,1)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64,128,1)\n",
        "        self.conv3 = nn.Conv1d(128,1024,1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "       \n",
        "   def forward(self, input):\n",
        "        matrix3x3 = self.input_transform(input)\n",
        "        # batch matrix multiplication\n",
        "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
        "\n",
        "        matrix64x64 = self.feature_transform(xb)\n",
        "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "        xb = self.bn3(self.conv3(xb))\n",
        "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "        output = nn.Flatten(1)(xb)\n",
        "        return output, matrix3x3, matrix64x64"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6QWJXcwen8h"
      },
      "source": [
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self, classes=10):\n",
        "        super().__init__()\n",
        "        self.transform = Transform()\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, classes)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
        "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
        "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
        "        output = self.fc3(xb)\n",
        "        return self.logsoftmax(output), matrix3x3, matrix64x64"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkyaPczmesB7"
      },
      "source": [
        "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    bs = outputs.size(0)\n",
        "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs, 1, 1)\n",
        "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs, 1, 1)\n",
        "    if outputs.is_cuda:\n",
        "        id3x3 = id3x3.cuda()\n",
        "        id64x64 = id64x64.cuda()\n",
        "    diff3x3 = id3x3 - torch.bmm(m3x3, m3x3.transpose(1, 2))\n",
        "    diff64x64 = id64x64 - torch.bmm(m64x64, m64x64.transpose(1, 2))\n",
        "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3) + torch.norm(diff64x64)) / float(bs)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z1MWUGZeuvT",
        "outputId": "11653fd5-db22-4944-b107-9b6feb8c750c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlkp-Y1R5R9f"
      },
      "source": [
        "pointnet = PointNet()\n",
        "pointnet.to(device);"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zr6nGlU5U9f"
      },
      "source": [
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O35RYD7J5W6b"
      },
      "source": [
        "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
        "    for epoch in range(epochs): \n",
        "        pointnet.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
        "\n",
        "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # print every 10 mini-batches\n",
        "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
        "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        pointnet.eval()\n",
        "        correct = total = 0\n",
        "\n",
        "        # validation\n",
        "        if val_loader:\n",
        "            with torch.no_grad():\n",
        "                for data in val_loader:\n",
        "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "            val_acc = 100. * correct / total\n",
        "            print('Valid accuracy: %d %%' % val_acc)\n",
        "\n",
        "        # save the model\n",
        "        if save:\n",
        "            torch.save(pointnet.state_dict(), \"save_\"+str(epoch)+\".pth\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0RK40Wc5caI",
        "outputId": "5195a60a-0745-415f-93f3-8f101fe5614d"
      },
      "source": [
        "train(pointnet, train_loader, valid_loader,  save=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1, Batch:   10 /  125], loss: 1.982\n",
            "[Epoch: 1, Batch:   20 /  125], loss: 1.574\n",
            "[Epoch: 1, Batch:   30 /  125], loss: 1.373\n",
            "[Epoch: 1, Batch:   40 /  125], loss: 1.304\n",
            "[Epoch: 1, Batch:   50 /  125], loss: 1.138\n",
            "[Epoch: 1, Batch:   60 /  125], loss: 1.196\n",
            "[Epoch: 1, Batch:   70 /  125], loss: 1.106\n",
            "[Epoch: 1, Batch:   80 /  125], loss: 0.897\n",
            "[Epoch: 1, Batch:   90 /  125], loss: 1.025\n",
            "[Epoch: 1, Batch:  100 /  125], loss: 0.890\n",
            "[Epoch: 1, Batch:  110 /  125], loss: 0.783\n",
            "[Epoch: 1, Batch:  120 /  125], loss: 0.863\n",
            "Valid accuracy: 53 %\n",
            "[Epoch: 2, Batch:   10 /  125], loss: 0.780\n",
            "[Epoch: 2, Batch:   20 /  125], loss: 0.863\n",
            "[Epoch: 2, Batch:   30 /  125], loss: 0.853\n",
            "[Epoch: 2, Batch:   40 /  125], loss: 0.850\n",
            "[Epoch: 2, Batch:   50 /  125], loss: 0.805\n",
            "[Epoch: 2, Batch:   60 /  125], loss: 0.772\n",
            "[Epoch: 2, Batch:   70 /  125], loss: 0.833\n",
            "[Epoch: 2, Batch:   80 /  125], loss: 0.739\n",
            "[Epoch: 2, Batch:   90 /  125], loss: 0.730\n",
            "[Epoch: 2, Batch:  100 /  125], loss: 0.718\n",
            "[Epoch: 2, Batch:  110 /  125], loss: 0.804\n",
            "[Epoch: 2, Batch:  120 /  125], loss: 0.771\n",
            "Valid accuracy: 74 %\n",
            "[Epoch: 3, Batch:   10 /  125], loss: 0.697\n",
            "[Epoch: 3, Batch:   20 /  125], loss: 0.800\n",
            "[Epoch: 3, Batch:   30 /  125], loss: 0.620\n",
            "[Epoch: 3, Batch:   40 /  125], loss: 0.668\n",
            "[Epoch: 3, Batch:   50 /  125], loss: 0.562\n",
            "[Epoch: 3, Batch:   60 /  125], loss: 0.661\n",
            "[Epoch: 3, Batch:   70 /  125], loss: 0.603\n",
            "[Epoch: 3, Batch:   80 /  125], loss: 0.565\n",
            "[Epoch: 3, Batch:   90 /  125], loss: 0.603\n",
            "[Epoch: 3, Batch:  100 /  125], loss: 0.674\n",
            "[Epoch: 3, Batch:  110 /  125], loss: 0.575\n",
            "[Epoch: 3, Batch:  120 /  125], loss: 0.609\n",
            "Valid accuracy: 66 %\n",
            "[Epoch: 4, Batch:   10 /  125], loss: 0.556\n",
            "[Epoch: 4, Batch:   20 /  125], loss: 0.699\n",
            "[Epoch: 4, Batch:   30 /  125], loss: 0.600\n",
            "[Epoch: 4, Batch:   40 /  125], loss: 0.581\n",
            "[Epoch: 4, Batch:   50 /  125], loss: 0.576\n",
            "[Epoch: 4, Batch:   60 /  125], loss: 0.528\n",
            "[Epoch: 4, Batch:   70 /  125], loss: 0.634\n",
            "[Epoch: 4, Batch:   80 /  125], loss: 0.630\n",
            "[Epoch: 4, Batch:   90 /  125], loss: 0.544\n",
            "[Epoch: 4, Batch:  100 /  125], loss: 0.569\n",
            "[Epoch: 4, Batch:  110 /  125], loss: 0.495\n",
            "[Epoch: 4, Batch:  120 /  125], loss: 0.574\n",
            "Valid accuracy: 76 %\n",
            "[Epoch: 5, Batch:   10 /  125], loss: 0.487\n",
            "[Epoch: 5, Batch:   20 /  125], loss: 0.440\n",
            "[Epoch: 5, Batch:   30 /  125], loss: 0.488\n",
            "[Epoch: 5, Batch:   40 /  125], loss: 0.512\n",
            "[Epoch: 5, Batch:   50 /  125], loss: 0.499\n",
            "[Epoch: 5, Batch:   60 /  125], loss: 0.643\n",
            "[Epoch: 5, Batch:   70 /  125], loss: 0.512\n",
            "[Epoch: 5, Batch:   80 /  125], loss: 0.575\n",
            "[Epoch: 5, Batch:   90 /  125], loss: 0.529\n",
            "[Epoch: 5, Batch:  100 /  125], loss: 0.470\n",
            "[Epoch: 5, Batch:  110 /  125], loss: 0.530\n",
            "[Epoch: 5, Batch:  120 /  125], loss: 0.483\n",
            "Valid accuracy: 82 %\n",
            "[Epoch: 6, Batch:   10 /  125], loss: 0.459\n",
            "[Epoch: 6, Batch:   20 /  125], loss: 0.407\n",
            "[Epoch: 6, Batch:   30 /  125], loss: 0.521\n",
            "[Epoch: 6, Batch:   40 /  125], loss: 0.452\n",
            "[Epoch: 6, Batch:   50 /  125], loss: 0.496\n",
            "[Epoch: 6, Batch:   60 /  125], loss: 0.578\n",
            "[Epoch: 6, Batch:   70 /  125], loss: 0.559\n",
            "[Epoch: 6, Batch:   80 /  125], loss: 0.442\n",
            "[Epoch: 6, Batch:   90 /  125], loss: 0.482\n",
            "[Epoch: 6, Batch:  100 /  125], loss: 0.581\n",
            "[Epoch: 6, Batch:  110 /  125], loss: 0.466\n",
            "[Epoch: 6, Batch:  120 /  125], loss: 0.440\n",
            "Valid accuracy: 82 %\n",
            "[Epoch: 7, Batch:   10 /  125], loss: 0.431\n",
            "[Epoch: 7, Batch:   20 /  125], loss: 0.433\n",
            "[Epoch: 7, Batch:   30 /  125], loss: 0.362\n",
            "[Epoch: 7, Batch:   40 /  125], loss: 0.412\n",
            "[Epoch: 7, Batch:   50 /  125], loss: 0.548\n",
            "[Epoch: 7, Batch:   60 /  125], loss: 0.430\n",
            "[Epoch: 7, Batch:   70 /  125], loss: 0.387\n",
            "[Epoch: 7, Batch:   80 /  125], loss: 0.379\n",
            "[Epoch: 7, Batch:   90 /  125], loss: 0.517\n",
            "[Epoch: 7, Batch:  100 /  125], loss: 0.442\n",
            "[Epoch: 7, Batch:  110 /  125], loss: 0.377\n",
            "[Epoch: 7, Batch:  120 /  125], loss: 0.444\n",
            "Valid accuracy: 67 %\n",
            "[Epoch: 8, Batch:   10 /  125], loss: 0.460\n",
            "[Epoch: 8, Batch:   20 /  125], loss: 0.467\n",
            "[Epoch: 8, Batch:   30 /  125], loss: 0.360\n",
            "[Epoch: 8, Batch:   40 /  125], loss: 0.458\n",
            "[Epoch: 8, Batch:   50 /  125], loss: 0.508\n",
            "[Epoch: 8, Batch:   60 /  125], loss: 0.446\n",
            "[Epoch: 8, Batch:   70 /  125], loss: 0.484\n",
            "[Epoch: 8, Batch:   80 /  125], loss: 0.399\n",
            "[Epoch: 8, Batch:   90 /  125], loss: 0.483\n",
            "[Epoch: 8, Batch:  100 /  125], loss: 0.404\n",
            "[Epoch: 8, Batch:  110 /  125], loss: 0.361\n",
            "[Epoch: 8, Batch:  120 /  125], loss: 0.410\n",
            "Valid accuracy: 79 %\n",
            "[Epoch: 9, Batch:   10 /  125], loss: 0.355\n",
            "[Epoch: 9, Batch:   20 /  125], loss: 0.433\n",
            "[Epoch: 9, Batch:   30 /  125], loss: 0.396\n",
            "[Epoch: 9, Batch:   40 /  125], loss: 0.353\n",
            "[Epoch: 9, Batch:   50 /  125], loss: 0.366\n",
            "[Epoch: 9, Batch:   60 /  125], loss: 0.431\n",
            "[Epoch: 9, Batch:   70 /  125], loss: 0.391\n",
            "[Epoch: 9, Batch:   80 /  125], loss: 0.435\n",
            "[Epoch: 9, Batch:   90 /  125], loss: 0.409\n",
            "[Epoch: 9, Batch:  100 /  125], loss: 0.363\n",
            "[Epoch: 9, Batch:  110 /  125], loss: 0.471\n",
            "[Epoch: 9, Batch:  120 /  125], loss: 0.482\n",
            "Valid accuracy: 80 %\n",
            "[Epoch: 10, Batch:   10 /  125], loss: 0.487\n",
            "[Epoch: 10, Batch:   20 /  125], loss: 0.377\n",
            "[Epoch: 10, Batch:   30 /  125], loss: 0.318\n",
            "[Epoch: 10, Batch:   40 /  125], loss: 0.361\n",
            "[Epoch: 10, Batch:   50 /  125], loss: 0.428\n",
            "[Epoch: 10, Batch:   60 /  125], loss: 0.447\n",
            "[Epoch: 10, Batch:   70 /  125], loss: 0.340\n",
            "[Epoch: 10, Batch:   80 /  125], loss: 0.381\n",
            "[Epoch: 10, Batch:   90 /  125], loss: 0.361\n",
            "[Epoch: 10, Batch:  100 /  125], loss: 0.416\n",
            "[Epoch: 10, Batch:  110 /  125], loss: 0.321\n",
            "[Epoch: 10, Batch:  120 /  125], loss: 0.412\n",
            "Valid accuracy: 74 %\n",
            "[Epoch: 11, Batch:   10 /  125], loss: 0.344\n",
            "[Epoch: 11, Batch:   20 /  125], loss: 0.322\n",
            "[Epoch: 11, Batch:   30 /  125], loss: 0.288\n",
            "[Epoch: 11, Batch:   40 /  125], loss: 0.386\n",
            "[Epoch: 11, Batch:   50 /  125], loss: 0.301\n",
            "[Epoch: 11, Batch:   60 /  125], loss: 0.380\n",
            "[Epoch: 11, Batch:   70 /  125], loss: 0.373\n",
            "[Epoch: 11, Batch:   80 /  125], loss: 0.404\n",
            "[Epoch: 11, Batch:   90 /  125], loss: 0.338\n",
            "[Epoch: 11, Batch:  100 /  125], loss: 0.343\n",
            "[Epoch: 11, Batch:  110 /  125], loss: 0.505\n",
            "[Epoch: 11, Batch:  120 /  125], loss: 0.400\n",
            "Valid accuracy: 81 %\n",
            "[Epoch: 12, Batch:   10 /  125], loss: 0.449\n",
            "[Epoch: 12, Batch:   20 /  125], loss: 0.286\n",
            "[Epoch: 12, Batch:   30 /  125], loss: 0.439\n",
            "[Epoch: 12, Batch:   40 /  125], loss: 0.405\n",
            "[Epoch: 12, Batch:   50 /  125], loss: 0.306\n",
            "[Epoch: 12, Batch:   60 /  125], loss: 0.423\n",
            "[Epoch: 12, Batch:   70 /  125], loss: 0.412\n",
            "[Epoch: 12, Batch:   80 /  125], loss: 0.429\n",
            "[Epoch: 12, Batch:   90 /  125], loss: 0.310\n",
            "[Epoch: 12, Batch:  100 /  125], loss: 0.421\n",
            "[Epoch: 12, Batch:  110 /  125], loss: 0.319\n",
            "[Epoch: 12, Batch:  120 /  125], loss: 0.347\n",
            "Valid accuracy: 79 %\n",
            "[Epoch: 13, Batch:   10 /  125], loss: 0.313\n",
            "[Epoch: 13, Batch:   20 /  125], loss: 0.344\n",
            "[Epoch: 13, Batch:   30 /  125], loss: 0.308\n",
            "[Epoch: 13, Batch:   40 /  125], loss: 0.287\n",
            "[Epoch: 13, Batch:   50 /  125], loss: 0.310\n",
            "[Epoch: 13, Batch:   60 /  125], loss: 0.393\n",
            "[Epoch: 13, Batch:   70 /  125], loss: 0.349\n",
            "[Epoch: 13, Batch:   80 /  125], loss: 0.362\n",
            "[Epoch: 13, Batch:   90 /  125], loss: 0.368\n",
            "[Epoch: 13, Batch:  100 /  125], loss: 0.416\n",
            "[Epoch: 13, Batch:  110 /  125], loss: 0.318\n",
            "[Epoch: 13, Batch:  120 /  125], loss: 0.256\n",
            "Valid accuracy: 74 %\n",
            "[Epoch: 14, Batch:   10 /  125], loss: 0.270\n",
            "[Epoch: 14, Batch:   20 /  125], loss: 0.377\n",
            "[Epoch: 14, Batch:   30 /  125], loss: 0.343\n",
            "[Epoch: 14, Batch:   40 /  125], loss: 0.342\n",
            "[Epoch: 14, Batch:   50 /  125], loss: 0.286\n",
            "[Epoch: 14, Batch:   60 /  125], loss: 0.357\n",
            "[Epoch: 14, Batch:   70 /  125], loss: 0.339\n",
            "[Epoch: 14, Batch:   80 /  125], loss: 0.248\n",
            "[Epoch: 14, Batch:   90 /  125], loss: 0.311\n",
            "[Epoch: 14, Batch:  100 /  125], loss: 0.301\n",
            "[Epoch: 14, Batch:  110 /  125], loss: 0.342\n",
            "[Epoch: 14, Batch:  120 /  125], loss: 0.319\n",
            "Valid accuracy: 81 %\n",
            "[Epoch: 15, Batch:   10 /  125], loss: 0.360\n",
            "[Epoch: 15, Batch:   20 /  125], loss: 0.372\n",
            "[Epoch: 15, Batch:   30 /  125], loss: 0.363\n",
            "[Epoch: 15, Batch:   40 /  125], loss: 0.294\n",
            "[Epoch: 15, Batch:   50 /  125], loss: 0.225\n",
            "[Epoch: 15, Batch:   60 /  125], loss: 0.389\n",
            "[Epoch: 15, Batch:   70 /  125], loss: 0.354\n",
            "[Epoch: 15, Batch:   80 /  125], loss: 0.297\n",
            "[Epoch: 15, Batch:   90 /  125], loss: 0.260\n",
            "[Epoch: 15, Batch:  100 /  125], loss: 0.302\n",
            "[Epoch: 15, Batch:  110 /  125], loss: 0.400\n",
            "[Epoch: 15, Batch:  120 /  125], loss: 0.317\n",
            "Valid accuracy: 85 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZSbL1z96E7b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}